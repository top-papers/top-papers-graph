# ===== Course defaults (works out-of-the-box) =====
DOMAIN_ID=science

# LLM: recommended defaults for the course
# auto  -> try local Ollama if available, else g4f if installed, else mock
LLM_PROVIDER=auto
LLM_MODEL=auto
OLLAMA_BASE_URL=http://localhost:11434

# Embeddings: hash is always available; sentence-transformers is higher quality
EMBED_PROVIDER=hash
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
HASH_EMBED_DIM=384

# Optional external services (only needed for GraphRAG / multimodal stages)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=please_change_me

QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=

GROBID_URL=http://localhost:8070

# Polite API usage (recommended for OpenAlex/Crossref/NCBI)
CONTACT_EMAIL=
USER_AGENT=

# Demo store (retrieval few-shot)
DEMO_ENABLED=true

# Agentic mode for hypothesis generation
HYP_AGENT_ENABLED=true
HYP_AGENT_BACKEND=internal  # internal|smolagents
HYP_AGENT_MAX_STEPS=4

# smolagents settings (only used when HYP_AGENT_BACKEND=smolagents)
SMOL_MODEL_BACKEND=scireason  # scireason|g4f|transformers
SMOL_MODEL_ID=HuggingFaceTB/SmolLM2-1.7B-Instruct
SMOL_MAX_NEW_TOKENS=768
SMOL_DEVICE_MAP=
SMOL_TORCH_DTYPE=
SMOL_G4F_MODEL=auto
SMOL_EXECUTOR=local  # local|docker
SMOL_PRINT_STEPS=false

# Optional GNN mode (PyTorch Geometric) for candidate hypotheses
# Install: pip install -e ".[gnn]"  (and optionally pyg extensions from data.pyg.org)
HYP_GNN_ENABLED=false
HYP_GNN_EPOCHS=80
HYP_GNN_HIDDEN_DIM=64
HYP_GNN_LR=0.01
HYP_GNN_NODE_CAP=300
